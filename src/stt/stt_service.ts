// íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€
/* eslint-disable @typescript-eslint/no-unsafe-assignment */
/* eslint-disable @typescript-eslint/no-unsafe-member-access */
/* eslint-disable @typescript-eslint/no-unsafe-return */
/* eslint-disable @typescript-eslint/no-unsafe-call */
/* eslint-disable @typescript-eslint/no-unsafe-argument */
/* eslint-disable @typescript-eslint/no-unsafe-enum-comparison */
/* eslint-disable @typescript-eslint/no-unsafe-assignment */
/* eslint-disable @typescript-eslint/no-unsafe-member-access */
import { BadRequestException, Injectable, Logger } from '@nestjs/common';
import { GoogleSpeechProvider } from './providers/google-speech';
import { AudioProcessorUtil } from './utils/audio-processer';
import { TextProcessorUtil } from './utils/text_processor';
import { TranscriptionResult, STTResult } from './entities/transcription';
import { SpeechPatternsUtil } from './utils/speech-patterms';
import { PynoteService } from './providers/pynote.service';
import { DatabaseService } from '@/database/database.service';

@Injectable()
export class STTService {
    private readonly logger = new Logger(STTService.name);

    constructor(
        private readonly googleSpeechProvider: GoogleSpeechProvider,
        private readonly pynoteService: PynoteService,
        private readonly db: DatabaseService,
    ) {}

    async transcribeAudioBuffer(
        audioBuffer: Buffer,
        mimeType = 'audio/wav',
        sessionStartTimeOffset = 0,
        gcsUrl?: string,
        usePynoteDiarization = false,
    ): Promise<STTResult> {
        if (usePynoteDiarization && gcsUrl) {
            return await this.transcribeAudioFromGcs(
                gcsUrl,
                mimeType,
                sessionStartTimeOffset,
                true,
            );
        }

        // ê¸°ì¡´ ë°©ì‹
        const base64Data = audioBuffer.toString('base64');
        const audioData = this.prepareAudioData(base64Data, gcsUrl);
        const config = this.createAudioConfig(mimeType);
        const result = await this.googleSpeechProvider.transcribe(audioData, config, gcsUrl);

        return this.adjustTimings(result, sessionStartTimeOffset);
    }

    // 82ë¼ì¸ë¶€í„° 127ë¼ì¸ê¹Œì§€ êµì²´
    private async transcribeWithPynoteDiarizationFromGcs(
        gcsUrl: string,
        mimeType: string,
        sessionStartTimeOffset: number,
        canvasId: string,
        mentorIdx?: number,
        menteeIdx?: number,
    ): Promise<STTResult> {
        try {
            this.logger.log('pynote GCS ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ + ë³‘ë ¬ STT ì‹œì‘');

            // 1. pynoteì—ì„œ GCS URLë¡œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬
            const segmentResult = await this.pynoteService.getSegmentsFromGcs(
                gcsUrl,
                canvasId,
                mentorIdx || 1,
                menteeIdx || 2,
                sessionStartTimeOffset,
            );

            if (!segmentResult.success || segmentResult.segments.length === 0) {
                throw new Error('pynote ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ ì‹¤íŒ¨');
            }

            this.logger.log(
                `pynote ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ ì™„ë£Œ: ${segmentResult.segments.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸`,
            );

            // 2. ë³‘ë ¬ STT ì²˜ë¦¬ (ìˆœì„œ ë³´ì¥)
            const parallelStartTime = Date.now();

            const sttPromises = segmentResult.segments.map(async (segment, originalIndex) => {
                if (process.env.NODE_ENV === 'development') {
                    this.logger.log(`ì„¸ê·¸ë¨¼íŠ¸ ${originalIndex + 1} STT ì²˜ë¦¬ ì‹œì‘ (ë³‘ë ¬)`);
                }

                try {
                    const audioBuffer = Buffer.from(segment.audioBuffer, 'base64');
                    const base64Data = audioBuffer.toString('base64');
                    const audioData = this.prepareAudioData(base64Data, '');
                    const config = this.createAudioConfigWithoutDiarization(mimeType);

                    const sttResult = await this.googleSpeechProvider.transcribe(audioData, config);

                    if (process.env.NODE_ENV === 'development') {
                        this.logger.log(`ì„¸ê·¸ë¨¼íŠ¸ ${originalIndex + 1} STT ì™„ë£Œ`);
                    }

                    return {
                        originalIndex,
                        segment,
                        sttResult,
                        success: true,
                    };
                } catch (error) {
                    this.logger.error(`ì„¸ê·¸ë¨¼íŠ¸ ${originalIndex + 1} STT ì‹¤íŒ¨:`, error);
                    return {
                        originalIndex,
                        segment,
                        error,
                        success: false,
                    };
                }
            });

            // 3. ë³‘ë ¬ ì‹¤í–‰ í›„ ìˆœì„œ ë³µì›
            this.logger.log(`${segmentResult.segments.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘...`);
            const results = await Promise.allSettled(sttPromises);
            const parallelTime = Date.now() - parallelStartTime;

            const successResults = results
                .filter(
                    (result): result is PromiseFulfilledResult<any> =>
                        result.status === 'fulfilled' && result.value.success,
                )
                .map((result) => result.value)
                .sort((a, b) => a.originalIndex - b.originalIndex);

            this.logger.log(
                `ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: ${successResults.length}/${segmentResult.segments.length}ê°œ ì„±ê³µ, ì†Œìš”ì‹œê°„: ${parallelTime}ms`,
            );

            // 4. ê²°ê³¼ ì¡°í•© (ì „ì²´ í…ìŠ¤íŠ¸ ìš°ì„  ì‚¬ìš©)
            const allSpeakers: Array<{
                text_Content: string;
                startTime: number;
                endTime: number;
                speakerTag: number;
                confidence?: number;
            }> = [];

            for (const { segment, sttResult } of successResults) {
                const baseStartTime = sessionStartTimeOffset + segment.startTime;

                // ğŸ†• ì „ì²´ í…ìŠ¤íŠ¸ ìš°ì„  ì‚¬ìš© ì „ëµ
                if (sttResult.transcript && sttResult.transcript.trim()) {
                    // ì „ì²´ transcriptê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                    allSpeakers.push({
                        text_Content: sttResult.transcript.trim(),
                        speakerTag: segment.speakerTag,
                        startTime: baseStartTime,
                        endTime: sessionStartTimeOffset + segment.endTime,
                        confidence: sttResult.confidence || 0.9,
                    });
                } else if (sttResult.speakers && sttResult.speakers.length > 0) {
                    // transcriptê°€ ì—†ìœ¼ë©´ speakers ë°°ì—´ ì‚¬ìš©
                    for (const speaker of sttResult.speakers) {
                        allSpeakers.push({
                            text_Content: speaker.text_Content || '',
                            speakerTag: segment.speakerTag,
                            startTime: baseStartTime + (speaker.startTime || 0),
                            endTime: baseStartTime + (speaker.endTime || 0),
                            confidence: speaker.confidence || 0.9,
                        });
                    }

                    const speakersText = sttResult.speakers.map((s) => s.text_Content).join(' ');
                    this.logger.log(`speakers ë°°ì—´ ì‚¬ìš©: "${speakersText.substring(0, 50)}..."`);
                } else {
                    // ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹ˆ í…ìŠ¤íŠ¸ë¡œ í”Œë ˆì´ìŠ¤í™€ë” ìƒì„±
                    allSpeakers.push({
                        text_Content: '[ìŒì„± ì¸ì‹ ì‹¤íŒ¨]',
                        speakerTag: segment.speakerTag,
                        startTime: baseStartTime,
                        endTime: sessionStartTimeOffset + segment.endTime,
                        confidence: 0.1,
                    });

                    this.logger.warn(`âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸ ì—†ìŒ, í”Œë ˆì´ìŠ¤í™€ë” ìƒì„±`);
                }
            }

            // 5. ìµœì¢… startTime ê¸°ì¤€ ì •ë ¬
            allSpeakers.sort((a, b) => a.startTime - b.startTime);

            // 6. ê²°ê³¼ ë°˜í™˜
            const combinedTranscript = allSpeakers
                .map((s) => s.text_Content)
                .filter((text) => text && text !== '[ìŒì„± ì¸ì‹ ì‹¤íŒ¨]')
                .join(' ');

            this.logger.log(
                `âœ… pynote ë³‘ë ¬ STT ì²˜ë¦¬ ì™„ë£Œ: ${allSpeakers.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸, ì„±ê³µë¥ : ${((successResults.length / segmentResult.segments.length) * 100).toFixed(1)}%`,
            );

            return {
                transcript: combinedTranscript,
                confidence: 0.9,
                speakers: allSpeakers,
            };
        } catch (error: unknown) {
            this.logger.error(
                `pynote GCS ë³‘ë ¬ ì²˜ë¦¬ ì‹¤íŒ¨: ${error instanceof Error ? error.message : String(error)}`,
            );

            // fallback to Google Speech
            return await this.transcribeWithGoogleSpeech(gcsUrl, mimeType, sessionStartTimeOffset);
        }
    }

    // ï¿½ï¿½ Google Speech ì§ì ‘ ì‚¬ìš© (fallbackìš©)
    private async transcribeWithGoogleSpeech(
        gcsUrl: string,
        mimeType: string,
        sessionStartTimeOffset: number,
    ): Promise<STTResult> {
        try {
            this.logger.log('ğŸ”„ Google Speech ì§ì ‘ ì‚¬ìš© (fallback)');

            const audioData = this.prepareAudioData('', gcsUrl);
            const config = this.createAudioConfig(mimeType);
            const result = await this.googleSpeechProvider.transcribe(audioData, config, gcsUrl);

            return this.adjustTimings(result, sessionStartTimeOffset);
        } catch (error) {
            this.logger.error(
                `Google Speech fallback ì‹¤íŒ¨: ${error instanceof Error ? error.message : String(error)}`,
            );
            throw error;
        }
    }

    async transcribeAudioFromGcs(
        gcsUrl: string,
        mimeType = 'audio/wav',
        sessionStartTimeOffset = 0,
        usePynoteDiarization = true,
        canvasId?: string,
        mentorIdx?: number,
        menteeIdx?: number,
    ): Promise<STTResult> {
        if (usePynoteDiarization) {
            return await this.transcribeWithPynoteDiarizationFromGcs(
                gcsUrl,
                mimeType,
                sessionStartTimeOffset,
                canvasId || 'resume-room',
                mentorIdx,
                menteeIdx,
            );
        }

        // ê¸°ì¡´ ë°©ì‹ (GCS URL ì‚¬ìš©)
        const audioData = this.prepareAudioData('', gcsUrl);
        const config = this.createAudioConfig(mimeType);
        const result = await this.googleSpeechProvider.transcribe(audioData, config, gcsUrl);

        return this.adjustTimings(result, sessionStartTimeOffset);
    }

    // ğŸ†• í™”ìë¶„ë¦¬ ë¹„í™œì„±í™”ëœ ì„¤ì • ìƒì„±
    private createAudioConfigWithoutDiarization(mimeType: string) {
        const baseConfig = this.createAudioConfig(mimeType);
        return {
            ...baseConfig,
            enableSpeakerDiarization: false, // í™”ìë¶„ë¦¬ ë¹„í™œì„±í™”
            diarizationSpeakerCount: 0,
            enableWordTimeOffsets: true, // â† ì´ ì¤„ ì¶”ê°€!
        };
    }

    private prepareAudioData(base64Data: string, gcsUrl?: string): string {
        if (gcsUrl) {
            return AudioProcessorUtil.convertToGcsUri(gcsUrl);
        }
        // ì›ë˜ëŠ” ë‹¨ìˆœíˆ base64 ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í–ˆì„ ê²ƒ
        return base64Data; // â† ì´ì œ ì›ë˜ëŒ€ë¡œ ë‹¨ìˆœíˆ base64 ë°˜í™˜
    }

    private createAudioConfig(mimeType: string) {
        // MP4/M4A íŒŒì¼ì˜ ê²½ìš° ë‹¤ë¥¸ ì„¤ì • ì‚¬ìš©
        if (mimeType.includes('wav') || mimeType.includes('wav')) {
            return {
                encoding: 'LINEAR16', // MP3 ì¸ì½”ë”© ì‚¬ìš©
                sampleRate: 44100,
                languageCode: 'ko-KR',
                enableSpeakerDiarization: true,
                diarizationSpeakerCount: 2,
                enableAutomaticPunctuation: false,
                maxAlternatives: 1,
                speechContexts: [], // ë¹ˆ ë°°ì—´ë¡œ ì„¤ì •
            };
        }

        // ë‹¤ë¥¸ í¬ë§·ë“¤
        let encoding: 'LINEAR16' | 'MP3' | 'WEBM_OPUS' | 'FLAC' = 'LINEAR16';
        if (mimeType.includes('mp3')) {
            encoding = 'MP3';
        } else if (mimeType.includes('webm') || mimeType.includes('opus')) {
            encoding = 'WEBM_OPUS';
        } else if (mimeType.includes('flac')) {
            encoding = 'FLAC';
        }

        return {
            encoding,
            sampleRate: 44100,
            languageCode: 'ko-KR',
            enableSpeakerDiarization: true,
            diarizationSpeakerCount: 2,
            enableAutomaticPunctuation: true,
            minSpeakerCount: 2,
            maxSpeakerCount: 2,
            enableWordTimeOffsets: true, // ğŸ†• ì¶”ê°€
            useEnhanced: true,
            maxAlternatives: 1,
            speechContexts: SpeechPatternsUtil.SPEECH_CONTEXTS,
        };
    }

    private adjustTimings(result: TranscriptionResult, sessionStartTimeOffset: number): STTResult {
        // TranscriptionResultë¥¼ STTResultë¡œ ë³€í™˜
        let speakers: Array<{
            text_Content: string;
            startTime: number;
            endTime: number;
            speakerTag: number;
        }> =
            result.speakers?.map((speaker) => ({
                text_Content: speaker.text_Content,
                startTime: Math.round((speaker.startTime + sessionStartTimeOffset) * 10) / 10,
                endTime: Math.round((speaker.endTime + sessionStartTimeOffset) * 10) / 10,
                speakerTag: speaker.speakerTag,
            })) || [];

        // ì—‰ëš±í•œ ë‹¨ì–´ êµì • ë° ë¬¸ì¥ ê°œì„  ì ìš©
        speakers = TextProcessorUtil.processAndCorrectText(speakers);

        // ë¬¸ì¥ ì—°ê²°ì„± ê°œì„ 
        speakers = TextProcessorUtil.improveConversationFlow(speakers);

        const sttResult: STTResult = {
            transcript: result.transcript,
            confidence: result.confidence,
            speakers: speakers,
        };

        return sttResult;
    }

    // ê°„ë‹¨í•œ ì‚¬ìš©ì ì—­í•  í™•ì¸ í•¨ìˆ˜
    async getCanvasUserRoles(canvasId: string) {
        if (!canvasId) {
            throw new BadRequestException('canvasId is required');
        }

        // ìº”ë²„ìŠ¤ ì°¸ì—¬ì ì¡°íšŒ (ë” ê°„ë‹¨í•˜ê³  ì•ˆì „í•œ ë°©ë²•)
        const participants = await this.db.query<{ user_id: number; role: string }>(
            `SELECT user_id, role FROM canvas_participant WHERE canvas_id = ?`,
            [canvasId],
        );

        const mentor = participants.find((p) => p.role === 'owner')?.user_id;
        const mentee = participants.find((p) => p.role === 'editor')?.user_id;

        return {
            mentor,
            mentee,
        };
    }
}
